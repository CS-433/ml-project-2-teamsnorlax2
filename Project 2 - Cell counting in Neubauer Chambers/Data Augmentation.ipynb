{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23424,"status":"ok","timestamp":1640169162626,"user":{"displayName":"Nicholas Sperry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17478191746282896441"},"user_tz":-60},"id":"DoqOOeqsIrzB","outputId":"911e129b-267f-4c9e-fd6d-daef862a5ef1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/12swurGjFVTSgi6fpziRcJ-tqsj6OoBgK/ML team project/Project 2/Neubauer Chamber Automation\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/ML team project/Project 2/Neubauer Chamber Automation\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dgCZ9115tTC9"},"outputs":[],"source":["from skimage.transform import rotate, AffineTransform, warp\n","from skimage.filters import gaussian\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import os\n","\n","#Neubauer Cell and Mask paths\n","NEU_CELL_PATH = 'Data Set/Originals/Images/'\n","NEU_MASK_PATH = 'Data Set/Originals/Masks/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9fcGAxbynTar"},"outputs":[],"source":["#Get the paths to the original dataset\n","cell_paths = sorted(os.listdir(NEU_CELL_PATH))\n","mask_paths = os.listdir(NEU_MASK_PATH)\n","mask_paths = sorted([filename.replace('label','') for filename in mask_paths])\n","\n","#Make sure they match each other\n","for cp, mp in zip(cell_paths, mask_paths):\n","    if cp != mp:\n","        print(cp, mp)"]},{"cell_type":"markdown","metadata":{"id":"-5VESZlWq66Z"},"source":["# Data Augmentation for the UNet"]},{"cell_type":"markdown","metadata":{"id":"RHGle8hbrUkS"},"source":["This is the code used to augment the data set used to train the UNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hlgIo8Kky11H"},"outputs":[],"source":["#Function used to turn the masks to binary\n","def threshold(img):\n","    out = img.copy().astype(np.uint8)\n","    #Threshold\n","    thresh = out.max()//2\n","    out[out<thresh] = 0\n","    out[out>=thresh] = 255\n","\n","    #Some images are already grayscale, some aren't, so we check here\n","    if len(out.shape)>2:    \n","        out = cv2.cvtColor(out, cv2.COLOR_BGR2GRAY)\n","    #Sometimes after grayscale conversion we don't have a binary mask\n","    #this makes sure we do\n","    out[out>0] = 255\n","    return out"]},{"cell_type":"markdown","metadata":{"id":"UV1xR8jBCGeh"},"source":["Here we do the actual data augmentation, and save the new images to the `train_augmented/` folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":798108,"status":"ok","timestamp":1640175300035,"user":{"displayName":"Nicholas Sperry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17478191746282896441"},"user_tz":-60},"id":"DcoIoYTirY3W","outputId":"d38fdb28-19e5-4b6a-c2dd-cbafc537333d"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.PNG 1.PNG\n","10.PNG 10.PNG\n","11.PNG 11.PNG\n","12.PNG 12.PNG\n","13.jpeg 13.jpeg\n","14.jpeg 14.jpeg\n","15.jpeg 15.jpeg\n","16.PNG 16.PNG\n","17.PNG 17.PNG\n","18.PNG 18.PNG\n","19.PNG 19.PNG\n","2.PNG 2.PNG\n","20.PNG 20.PNG\n","21.PNG 21.PNG\n","22.PNG 22.PNG\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: UserWarning: ../cell-data/datasets/instagram/train_augmented/masks/151.jpg is a low contrast image\n"]},{"name":"stdout","output_type":"stream","text":["23.PNG 23.PNG\n","24.PNG 24.PNG\n","25.PNG 25.PNG\n","26.PNG 26.PNG\n","27.PNG 27.PNG\n","28.PNG 28.PNG\n","29.PNG 29.PNG\n","3.PNG 3.PNG\n","30.PNG 30.PNG\n","31.PNG 31.PNG\n","32.PNG 32.PNG\n","33.PNG 33.PNG\n","34.PNG 34.PNG\n","35.PNG 35.PNG\n","36.PNG 36.PNG\n","37.PNG 37.PNG\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: UserWarning: ../cell-data/datasets/instagram/train_augmented/masks/327.jpg is a low contrast image\n"]},{"name":"stdout","output_type":"stream","text":["38.PNG 38.PNG\n","39.PNG 39.PNG\n","4.PNG 4.PNG\n","40.PNG 40.PNG\n","41.PNG 41.PNG\n","42.PNG 42.PNG\n","43.PNG 43.PNG\n","5.PNG 5.PNG\n","53.PNG 53.PNG\n","54.PNG 54.PNG\n","55.PNG 55.PNG\n","56.PNG 56.PNG\n","57.PNG 57.PNG\n","58.PNG 58.PNG\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: UserWarning: ../cell-data/datasets/instagram/train_augmented/masks/481.jpg is a low contrast image\n"]},{"name":"stdout","output_type":"stream","text":["59.PNG 59.PNG\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:68: UserWarning: ../cell-data/datasets/instagram/train_augmented/masks/492.jpg is a low contrast image\n"]},{"name":"stdout","output_type":"stream","text":["6.PNG 6.PNG\n","60.PNG 60.PNG\n","61.PNG 61.PNG\n","7.PNG 7.PNG\n","77.PNG 77.PNG\n","8.PNG 8.PNG\n","9.PNG 9.PNG\n"]}],"source":["#Where we save the new images to\n","cell_out = 'Data Set/train_augmented/images/'\n","mask_out = 'Data Set/train_augmented/masks/'\n","i = 1\n","# Iterate over the original dataset\n","for cp, mp in zip(cell_paths, mask_paths):\n","    print(cp, mp)\n","    filename, ext = os.path.splitext(mp)\n","    mp = filename+'label'+ext\n","    \n","    # The first image has a bad mask, so we just skip over it entirely\n","    if cp == '1.PNG':\n","        continue\n","    \n","    #Load original image\n","    cell = cv2.imread(NEU_CELL_PATH + cp)\n","    mask = cv2.imread(NEU_MASK_PATH + mp)\n","\n","    #JPEGs are special, and the masks are inversed to we fix them here\n","    if ext in ['.jpeg','.jpg']:\n","        mask = 255-mask\n","\n","    # The second image has bad mask at the very top, so we just trim it\n","    if cp == '2.PNG':\n","        cell = cell[137:]\n","        mask = mask[137:]\n","\n","    #Turn mask to binary and save original images\n","    mask = threshold(mask)\n","    cv2.imwrite(cell_out + f'{i}.jpg', cell)\n","    cv2.imwrite(mask_out + f'{i}.jpg', mask)\n","    i+=1\n","    \n","    #Rotated 45ยบ\n","    cv2.imwrite(cell_out+f'{i}.jpg', (rotate(cell,angle=45,mode='wrap')*255).astype('uint8'))\n","    cv2.imwrite(mask_out+f'{i}.jpg', threshold(rotate(mask,angle=45,mode='wrap')*255))\n","    i+=1\n","\n","    #Flipped left-right\n","    cv2.imwrite(cell_out+f'{i}.jpg', np.fliplr(cell))\n","    cv2.imwrite(mask_out+f'{i}.jpg', np.fliplr(mask))\n","    i+=1\n","\n","    #Flipped up-down\n","    cv2.imwrite(cell_out+f'{i}.jpg', np.flipud(cell))\n","    cv2.imwrite(mask_out+f'{i}.jpg', np.flipud(mask))\n","    i+=1\n","\n","    #Blurred\n","    cv2.imwrite(cell_out+f'{i}.jpg', (gaussian(cell,sigma=5,multichannel=True)*255).astype('uint8'))\n","    cv2.imwrite(mask_out+f'{i}.jpg', mask)\n","    i+=1\n","\n","    #Darker\n","    cv2.imwrite(cell_out+f'{i}.jpg', (255*np.power(cell/255.0, 1.5)).astype('uint8'))\n","    cv2.imwrite(mask_out+f'{i}.jpg', mask)\n","    i+=1\n","\n","    #Brighter\n","    cv2.imwrite(cell_out+f'{i}.jpg', (255*np.power(cell/255.0, 0.7)).astype('uint8'))\n","    cv2.imwrite(mask_out+f'{i}.jpg', mask)\n","    i+=1\n","\n","    #### Compositions\n","    #Flipped LR + UD\n","    cv2.imwrite(cell_out+f'{i}.jpg', np.flipud(np.fliplr(cell)))\n","    io.imsave(mask_out+f'{i}.jpg', np.flipud(np.fliplr(mask)))\n","    i+=1\n","\n","    # Rotated + blurred\n","    cv2.imwrite(cell_out+f'{i}.jpg', (gaussian(rotate(cell,angle=45,mode='wrap'),sigma=5,multichannel=True)*255).astype('uint8'))\n","    cv2.imwrite(mask_out+f'{i}.jpg', threshold(rotate(mask,angle=45,mode='wrap')*255))\n","    i+=1\n","    # Rotated + LR\n","    cv2.imwrite(cell_out+f'{i}.jpg', np.fliplr(rotate(cell,angle=45,mode='wrap')*255).astype('uint8'))\n","    cv2.imwrite(mask_out+f'{i}.jpg', threshold(np.fliplr(rotate(mask,angle=45,mode='wrap')*255)))\n","    i+=1\n","\n","    # Rotated + UD\n","    cv2.imwrite(cell_out+f'{i}.jpg', np.flipud(rotate(cell,angle=45,mode='wrap')*255).astype('uint8'))\n","    cv2.imwrite(mask_out+f'{i}.jpg', threshold(np.flipud(rotate(mask,angle=45,mode='wrap')*255)))\n","    i+=1\n","\n"]},{"cell_type":"markdown","metadata":{"id":"TNjZvLuYrQ0Y"},"source":["# Data Augmentation for the Square Detection"]},{"cell_type":"markdown","metadata":{"id":"bKYTVrZFDJur"},"source":["This is the code used to get extra data for the Square Detection. Here we ignore the masks since we don't use them for the actual square detection. We do not use Rotation here either, as the algorithm can't detected rotated squares :(.\n","These images are saved to the `train_augmented/images/no-rotation/` folder"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351326,"status":"ok","timestamp":1640132763980,"user":{"displayName":"Nicholas Sperry","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17478191746282896441"},"user_tz":-60},"id":"PaXEDlGvI95H","outputId":"1c1d7fd1-0322-4bb3-ebc6-533928418677"},"outputs":[{"name":"stdout","output_type":"stream","text":["1.PNG 1\n","10.PNG 10\n","11.PNG 11\n","12.PNG 12\n","13.png 13\n","14.png 14\n","15.png 15\n","16.PNG 16\n","17.PNG 17\n","18.PNG 18\n","2.PNG 2\n","20.PNG 20\n","21.PNG 21\n","23.PNG 23\n","24.PNG 24\n","25.PNG 25\n","26.PNG 26\n","27.PNG 27\n","28.PNG 28\n","29.png 29\n","30.png 30\n","31.PNG 31\n","32.PNG 32\n","33.PNG 33\n","34.png 34\n","35.PNG 35\n","36.png 36\n","37.png 37\n","38.png 38\n","4.PNG 4\n","40.png 40\n","41.png 41\n","43.png 43\n","5.PNG 5\n","53.png 53\n","54.png 54\n","55.png 55\n","58.PNG 58\n","6.PNG 6\n","60.png 60\n","61.png 61\n","7.PNG 7\n","8.PNG 8\n","9.PNG 9\n"]}],"source":["cell_out = 'Data set/Square detection/Cropped-augmented-norotation/'\n","\n","#Iterate over original images\n","for cp in cell_paths:\n","    i, ext = os.path.splitext(cp)\n","    print(cp, i)\n","    \n","    #Original\n","    cell = cv2.imread(NEU_CELL_PATH + cp)\n","    cv2.imwrite(cell_out + f'{i}_original.png', cell)\n","    \n","    #Flipped left-right\n","    cv2.imwrite(cell_out+f'{i}_flippedLR.png', np.fliplr(cell))\n","    \n","    #Flipped up-down\n","    cv2.imwrite(cell_out+f'{i}_flippedUD.png', np.flipud(cell))\n","   \n","    #Blurred\n","    cv2.imwrite(cell_out+f'{i}_blurred.png', (gaussian(cell,sigma=5,multichannel=True)*255).astype(np.uint8))\n","\n","    #Darker\n","    cv2.imwrite(cell_out+f'{i}_darker.png', 255*np.power(cell/255.0, 1.5))\n","    \n","    #Brighter\n","    cv2.imwrite(cell_out+f'{i}_brighter.png', 255*np.power(cell/255.0, 0.7))\n","    \n","    #### Compositions\n","    #Flipped LR + UD\n","    cv2.imwrite(cell_out+f'{i}_flippedLR+UD.png', np.flipud(np.fliplr(cell)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZxC3QcEUtAjk"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMPBaYD6J8/9GtInXFaV+uL","collapsed_sections":[],"name":"Data Augmentation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
